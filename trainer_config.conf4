#!/usr/bin/env python
#-*-python-*-
# vim: ft=python
#!/usr/bin/env python

cluster_config(
        fs_name="hdfs://nmg01-mulan-hdfs.dmop.baidu.com:54310",
    fs_ugi="idl-vrt,VRTData@2016",
	train_data_path="/app/idl/users/vrt/lizhichao/train_data_proto_0926",
    #train_data_path="/app/idl/users/vrt/lizhichao/train_data_all_1009",
	test_data_path="hdfs://nmg01-mulan-hdfs.dmop.baidu.com:54310/app/idl/users/vrt/lizhichao/prototest",
    output_path="/app/idl/users/vrt/lizhichao/model_1010_remote_sparse_proto_test",
    use_remote_sparse = True,
)

import math
import logging

Settings(
  algorithm='sgd',
  learning_rate=5e-03,
  learning_method = 'adagrad',
  ada_epsilon = 1e-6,
  ada_rou = 0.95,
  batch_size = 4,
  learning_rate_decay_a=0,
  learning_rate_decay_b=0,
)

#TrainData(ProtoData(files="train.list",type="proto"))
#TrainData(PyData(files = "train.list", load_data_module = "pydata", load_data_object = "processData"))
TestData(ProtoData(files="test.list",type="proto"))


Inputs("f0","f1","f2","f3","label")
Outputs("cost")

hidden_dim = 128

output_dim = 64

#default_decay_rate(8e-4)
#default_initial_std(1/math.sqrt(hidden_dim)/3.0)
lr_hid_col = 0.1

fealens = [200,200,9246,970]

Layer(
    name = "f3",
    type = "data",
    size = fealens[3],
)
  
for i in range(3):
  fea = 'f' + str(i)
  Layer(
      name = fea,
      type = "data",
      size = fealens[i],
  )
  
  Layer(
      name = "emb_" + str(i),
      type = "fc",
      active_type='stanh',
      size = hidden_dim,
      bias = False,
      drop_rate = 0.6,
      inputs = Input(fea, initial_std = 1.0 / math.sqrt(fealens[i]) / 3.0, parameter_name = "_emb_" + str(i)),
  ) 

for k in range(1):
  for i in range(2):
    Layer(
        name = "cos" + str(k) + str(i + 1),
        type = "fc",
        active_type='',
        size = hidden_dim,
        inputs = [
          #Input("emb_"+str(k), initial_std = 1.0 / math.sqrt(hidden_dim)),
          Input("emb_"+str(i + 1), initial_std = 1.0 / math.sqrt(hidden_dim)),
        ]
    )
    Layer(
		name = "dot_mul_layer"+ str(i+1), 
		type = "mixed",
		active_type='',
		bias = False,
		size = hidden_dim,
		inputs = DotMulOperator([
			"emb_"+str(k),"cos" + str(k) + str(i + 1),
		])
	)
    embd_input=[]
    for t in range(hidden_dim):
      Layer(
		   inputs = [IdentityOffsetProjection("dot_mul_layer"+ str(i+1),offset=t)],
		   name = "aa"+str(i+1)+str(t),
		   bias = False,
		   type = "mixed",
		   active_type = "",
		   size = 1
	      )
      embd_input.append("aa"+str(i+1)+str(t))
	#logging.info("shape"+str(len(embd_input)))
    Layer(
		inputs = embd_input,
		name = "addto_layer"+ str(i+1), 
		#bias = Bias(parameter_name = "addto_layer.bias"+ str(i+1)), 
		active_type = "", 
		#size = 1,
		type = "addto"
	)
	
  Layer(
    inputs = [Input("addto_layer1"), Input("addto_layer2")], 
    name = "concat_layer", 
    active_type = "",
    type = "concat"
    )
  Layer(
      name = "norm_cosine_"+str(k),
      type = "mixed",
      size = 2,
      active_type = "softmax",
      #  bias = False,
      inputs = IdentityProjection("concat_layer"),      
  )
  
  for i in range(2):
    Layer(
      inputs = [IdentityOffsetProjection("norm_cosine_"+str(k),offset=i)],
      name = "attw"+str(k)+str(i+1),
      bias = False,
      type = "mixed",
      active_type = "",
      size = 1
    )
  
  for i in range(2):
    Layer(
        name = "context_vectors"+str(k)+str(i+1),
        type = "scaling",
        inputs = ["attw"+str(k)+str(i+1),
                  "emb_"+str(i+1)],
        )
  
  avgInputs = []
  for i in range(2):
    avgInputs.append(Input("context_vectors"+str(k)+str(i+1)))
  
  Layer(
      name = "context"+str(k),
      type = "addto",
      active_type = "stanh",
      inputs = avgInputs,
      )
  
  Layer(
      name = "finalcos"+str(k),
      type = "fc",
      size = output_dim,
      active_type = "stanh",
      inputs = [Input("emb_"+str(k),initial_std=1/math.sqrt(output_dim)), Input("context"+str(k),initial_std=1/math.sqrt(output_dim))],
  )


FCLayer(
    name = "output",
    size = 2,
    active_type = "softmax",
    bias = Bias(initial_std = 0, parameter_name = '_output_bias'),
    #bias = False,
    inputs = [
        Input("finalcos0",initial_std = 1.0/math.sqrt(output_dim)),
        ]
)

Layer(
    name = "label",
    type = "data",
    size = 1,
)

Layer(
    name = "cost",
    type = "multi-class-cross-entropy",
    inputs = [ "output","label"],
)

Evaluator(
    name = "mis_classification", 
    type = "classification_error", 
    inputs = ["output", "label"]
)

Evaluator(
    name = "pre_rec",
    type = "precision_recall",
    positive_label = 1,
    inputs = ["output", "label"]
)

Evaluator(
    inputs = ["output", "label"], 
    name = "auc", 
    type = "last-column-auc"
)
